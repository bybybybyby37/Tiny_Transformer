{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be51c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Pytorch\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install torch==2.2.2+cu118 torchvision==0.17.2+cu118 torchaudio==2.2.2+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
    "#!{sys.executable} -m pip install tensorboard==2.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c0a470b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\nimport torchvision\\nprint(f\"PyTorch version Installed: {torch.__version__}\\nTorchvision version Installed: {torchvision.__version__}\\n\")\\nif not torch.__version__.startswith(\"2.2\"):\\n    print(\"you are using an another version of PyTorch. We expect PyTorch 2.2. You may continue using your version but it\"\\n          \" might cause dependency and compatibility issues.\")\\nif not torchvision.__version__.startswith(\"0.17\"):\\n    print(\"you are using an another version of torchvision. We expect torchvision 0.17. You can continue with your version but it\"\\n          \" might cause dependency and compatibility issues.\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "import torchvision\n",
    "print(f\"PyTorch version Installed: {torch.__version__}\\nTorchvision version Installed: {torchvision.__version__}\\n\")\n",
    "if not torch.__version__.startswith(\"2.2\"):\n",
    "    print(\"you are using an another version of PyTorch. We expect PyTorch 2.2. You may continue using your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "if not torchvision.__version__.startswith(\"0.17\"):\n",
    "    print(\"you are using an another version of torchvision. We expect torchvision 0.17. You can continue with your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import requests\n",
    "\n",
    "from models import tokenizer\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # To prevent the kernel from dying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f8d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiny Shakespeare downloaded! File size: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "text = requests.get(url).text\n",
    "\n",
    "with open(\"data/tiny_shakespeare.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"Tiny Shakespeare downloaded! File size:\", len(text), \"characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23206f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique chars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsample = \"ROMEO:\"\\nids = tok.encode(sample)\\nprint(\"Encoded:\", ids)\\nprint(\"Decoded:\", tok.decode(ids))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer\n",
    "with open(\"data/tiny_shakespeare.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "tok = tokenizer.CharTokenizer(text)\n",
    "print(len(tok.chars), \"unique chars\")\n",
    "\n",
    "#Sample Test\n",
    "'''\n",
    "sample = \"ROMEO:\"\n",
    "ids = tok.encode(sample)\n",
    "print(\"Encoded:\", ids)\n",
    "print(\"Decoded:\", tok.decode(ids))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 1,115,394\n",
      "Train: 669,236, Val: 223,078, Test: 223,080\n"
     ]
    }
   ],
   "source": [
    "ids = tok.encode(text)\n",
    "data = torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "# Split by 6:2:2\n",
    "n = len(data)\n",
    "n_train = int(0.6 * n)\n",
    "n_val = int(0.2 * n)\n",
    "n_test = n - n_train - n_val\n",
    "\n",
    "train_data = data[:n_train]\n",
    "val_data = data[n_train:n_train + n_val]\n",
    "test_data = data[n_train + n_val:]\n",
    "\n",
    "print(f\"Total tokens: {n:,}\")\n",
    "print(f\"Train: {len(train_data):,}, Val: {len(val_data):,}, Test: {len(test_data):,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
